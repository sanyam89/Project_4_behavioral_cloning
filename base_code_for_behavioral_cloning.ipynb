{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL.PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import math\n",
    "from random import shuffle\n",
    "from PIL import Image\n",
    "\n",
    "samples = []\n",
    "with open('../../opt/carnd_p3/data/driving_log.csv') as csvfile:\n",
    "# with open('../data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "    print('csv file read successfully')\n",
    "    print(samples[1440])\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "def process_image(img):\n",
    "    #do no preprocessing for now\n",
    "    return img\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    #print('sample size = ', num_samples)\n",
    "    \n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        steer_correction = 0.2\n",
    "\n",
    "            \n",
    "        for offset in range(1, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            \n",
    "            #batch_samples[np.isnan(batch_samples)]=0\n",
    "            \n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            #print('batch sample size',len(batch_samples))\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "#                print('Batch sample vlaue = ',batch_sample[3])\n",
    "                steering_center = float(batch_sample[3])\n",
    "                steering_left = steering_center + steer_correction\n",
    "                steering_right = steering_center - steer_correction\n",
    "            \n",
    "                #source_path = batch_sample[0] # loading center image only\n",
    "                #filename = source_path.split('/')[-1]\n",
    "                #print('filename=',filename)\n",
    "                current_path = '../../opt/carnd_p3/data/IMG/'\n",
    "                #print ('current path = ',current_path)\n",
    "                img_center = process_image(np.asarray(Image.open(current_path + batch_sample[0].split('/')[-1])))\n",
    "                img_left = process_image(np.asarray(Image.open(current_path + batch_sample[1].split('/')[-1])))\n",
    "                img_right = process_image(np.asarray(Image.open(current_path + batch_sample[2].split('/')[-1])))\n",
    "            \n",
    "                images.extend([img_center, img_left, img_right])\n",
    "                angles.extend([steering_center, steering_left, steering_right])\n",
    "            #print('total images for this batch = ', np.array(images).size)\n",
    "            #print('total angles for this batch = ', np.array(angles).size)\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "# Set our batch size\n",
    "batch_size=32\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=batch_size)\n",
    "validation_generator = generator(validation_samples, batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda\n",
    "from keras.layers import Conv2D, Cropping2D\n",
    "#from keras.layers.pooling\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(160,320,3)))\n",
    "model.add(Lambda(lambda x:x/255-0.5))\n",
    "print('model shape after lambda = ', model.output_shape)\n",
    "#for layer in model.layers:\n",
    "#    print(layer.output_shape)\n",
    "model.add(Conv2D(24,5,5,subsample=(2,2),activation='relu'))\n",
    "model.add(Conv2D(36,5,5,subsample=(2,2),activation='relu'))\n",
    "model.add(Conv2D(48,5,5,subsample=(2,2),activation='relu'))\n",
    "model.add(Conv2D(64,3,3,activation='relu'))\n",
    "model.add(Conv2D(64,3,3,activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "print('model shape after dense = ',model.output_shape)\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "#model.fit(X_train, y_train, validation_split = 0.25, shuffle = True, nb_epoch=7)\n",
    "model.fit_generator(train_generator, steps_per_epoch=math.ceil(len(train_samples)/batch_size)*3, validation_data=validation_generator, validation_steps=math.ceil(len(validation_samples)/batch_size)*3, epochs=5, verbose=1)\n",
    "\n",
    "model.save('model_01.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERROR that I am getting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(/opt/carnd_p3/behavioral) root@e2c06358fe1e:/home/workspace# python model.py\n",
    "csv file read successfully\n",
    "['IMG/center_2016_12_01_13_35_04_080.jpg', ' IMG/left_2016_12_01_13_35_04_080.jpg', ' IMG/right_2016_12_01_13_35_04_080.jpg'\n",
    ", ' 0.0904655', ' 0.9855326', ' 0', ' 30.18644']\n",
    "Using TensorFlow backend.\n",
    "model shape after lambda =  (None, 90, 320, 3)\n",
    "model.py:88: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), strides=(2, 2), activation=\"relu\n",
    "\")`\n",
    "  model.add(Conv2D(24,5,5,subsample=(2,2),activation='relu'))\n",
    "model.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), strides=(2, 2), activation=\"relu\n",
    "\")`\n",
    "  model.add(Conv2D(36,5,5,subsample=(2,2),activation='relu'))\n",
    "model.py:90: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), strides=(2, 2), activation=\"relu\")`\n",
    "  model.add(Conv2D(48,5,5,subsample=(2,2),activation='relu'))\n",
    "model.py:91: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
    "  model.add(Conv2D(64,3,3,activation='relu'))\n",
    "model.py:92: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
    "  model.add(Conv2D(64,3,3,activation='relu'))\n",
    "model shape after dense =  (None, 1)\n",
    "Epoch 1/5\n",
    "2019-07-15 18:11:28.303843: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "2019-07-15 18:11:28.303906: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "2019-07-15 18:11:28.303918: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
    "2019-07-15 18:11:28.303927: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
    "2019-07-15 18:11:28.303935: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
    "2019-07-15 18:11:28.408961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2019-07-15 18:11:28.409710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: \n",
    "name: Tesla K80\n",
    "major: 3 minor: 7 memoryClockRate (GHz) 0.8235\n",
    "pciBusID 0000:00:04.0\n",
    "Total memory: 11.17GiB\n",
    "Free memory: 11.09GiB\n",
    "2019-07-15 18:11:28.409769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 \n",
    "2019-07-15 18:11:28.409796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y \n",
    "2019-07-15 18:11:28.409823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0)\n",
    "164/603 [=======>......................] - ETA: 2:38 - loss: 0.0235Traceback (most recent call last):\n",
    "  File \"model.py\", line 102, in <module>\n",
    "    model.fit_generator(train_generator, steps_per_epoch=math.ceil(len(train_samples)/batch_size)*3, validation_data=validation_generator, validation_steps=math.ceil(len(validation_samples)/batch_size)*3, epochs=5, verbose=1)\n",
    "  File \"/opt/carnd_p3/behavioral/lib/python3.5/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n",
    "    return func(*args, **kwargs)\n",
    "  File \"/opt/carnd_p3/behavioral/lib/python3.5/site-packages/keras/engine/training.py\", line 1418, in fit_generator\n",
    "    initial_epoch=initial_epoch)\n",
    "  File \"/opt/carnd_p3/behavioral/lib/python3.5/site-packages/keras/engine/training_generator.py\", line 181, in fit_generator\n",
    "    generator_output = next(output_generator)\n",
    "  File \"/opt/carnd_p3/behavioral/lib/python3.5/site-packages/keras/utils/data_utils.py\", line 709, in get\n",
    "    six.reraise(*sys.exc_info())\n",
    "  File \"/opt/carnd_p3/behavioral/lib/python3.5/site-packages/six.py\", line 693, in reraise\n",
    "    raise value\n",
    "  File \"/opt/carnd_p3/behavioral/lib/python3.5/site-packages/keras/utils/data_utils.py\", line 685, in get\n",
    "    inputs = self.queue.get(block=True).get()\n",
    "  File \"/opt/carnd_p3/behavioral/lib/python3.5/multiprocessing/pool.py\", line 608, in get\n",
    "    raise self._value\n",
    "  File \"/opt/carnd_p3/behavioral/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n",
    "    result = (True, func(*args, **kwds))\n",
    "  File \"/opt/carnd_p3/behavioral/lib/python3.5/site-packages/keras/utils/data_utils.py\", line 626, in next_sample\n",
    "    return six.next(_SHARED_SEQUENCES[uid])\n",
    "  File \"model.py\", line 47, in generator\n",
    "    steering_center = float(batch_sample[3])\n",
    "ValueError: could not convert string to float: 'steering'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
